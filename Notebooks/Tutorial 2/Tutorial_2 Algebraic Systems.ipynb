{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Algebraic Equations (Linear and Non-Linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In engineering problems (be it reactor design or process control), we are often tasked with finding a **model** of the system, which describes the dynamic physical/chemical/mechanical etc. relationships between the relevant variables.\n",
    "\n",
    "The simplest models can be expressed using **algebraic equations**, which invoke simple mathematical operations on the variables, and no calculus such as differentiation or integration. These models can be further divided into **linear** and **non-linear** models as follows:\n",
    "\n",
    "* **Linear** - involves only addition and subtraction of variables\n",
    "* **Non-Linear** - involves polynomial, trigonometric, logarithmic, and-or inter-coupling between variables\n",
    "\n",
    "The first type of system (**linear**) is relatively easy to solve using linear algebra and matrix manipulations. Let's discuss how to do this in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Solving linear systems of equations\n",
    "Suppose we have the following three equations which describe a linear system between the variables $x_1$, $x_2$, and $x_3$:\n",
    "\n",
    "$x_1+x_2+x_3 = 10$\n",
    "$2x_1+x_2+x_3 = 5$\n",
    "$-x_1+2x_2+4x_3 = 4$\n",
    "\n",
    "In Math 152 (or any equivalent introductary linear algebra course) you may have learned to solve this using Gaussian elimination and back-substitution. However, all these steps can be easily bypassed by using Python's built-in functions:\n",
    "\n",
    "$A = \\begin{bmatrix} 1 & 1 & 1 \\\\\n",
    "2 & 1 & 1 \\\\\n",
    "-1 & 2 & 4 \n",
    "\\end{bmatrix}$,\n",
    "$b = \\begin{bmatrix} 10 \\\\\n",
    "5 \\\\\n",
    "4\n",
    "\\end{bmatrix}$\n",
    "\n",
    "The solution is $A^{-1}b$ which we now compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt # for plots\n",
    "import numpy as np # for most computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -5. ]\n",
      " [ 30.5]\n",
      " [-15.5]]\n"
     ]
    }
   ],
   "source": [
    "# Define matrices\n",
    "A = np.array([[1,1,1],[2,1,1],[-1,2,4]])\n",
    "b = np.array([[10],[5],[4]])\n",
    "\n",
    "# Find solution\n",
    "x = np.linalg.solve(A,b)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was pretty straightforward. As a sanity check, let's compute $Ax$ and see whether that indeed equals b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.]\n",
      " [ 5.]\n",
      " [ 4.]]\n",
      "[[10]\n",
      " [ 5]\n",
      " [ 4]]\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(A,x))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed the answer is correct as shown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases the $A$ matrix might be *non-invertible*. In other words, the *rank* of $A$ (i.e. number of independent rows or columns) is less than its maximum size. Consider the examples below:\n",
    "\n",
    "$$A_1 = \\begin{bmatrix} 1 & 1 & 1 \\\\\n",
    "1 & 1 & 1 \\\\\n",
    "-1 & 2 & 4 \n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$$A_2 = \\begin{bmatrix} 1 & 1 & 1 \\\\\n",
    "-1 & 2 & 4 \n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$$A_3 = \\begin{bmatrix} 1 & 1 & 1 \\\\\n",
    "2 & 1 & 1 \\\\\n",
    "-1 & 2 & 4 \\\\\n",
    "1 & 2 & 5\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix $A_1$ is non-invertible, as confirmed by evaluating its determinant and/or its eigenvalues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[-4.44089210e-16  1.58578644e+00  4.41421356e+00]\n"
     ]
    }
   ],
   "source": [
    "A1 = np.array([[1,1,1],[1,1,1],[-1,2,4]])\n",
    "print(np.linalg.det(A1))\n",
    "print(np.linalg.eigvals(A1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the determinant of a square matrix is the product of its eigenvalues. If any single eigenvalue is equal to zero (to the closest precision), then the matrix is non-invertible.\n",
    "\n",
    "But what about matrices $A_2$ and $A_3$? The rank of matrix $A_2$ is 2, but it has 3 columns. Therefore it corresponds to an *underdefined* problem where there are more variables (3) than equations (2). The opposite is true for $A_3$ - this corresponds to an *overdefined* problem where there are more equations than variables, unless one of the equations is a linear combination of the remainder. \n",
    "\n",
    "Although the inverse of a non-square matrix is undefined, we can still compute solutions to these problems using a neat trick, something similar to an inverse. This known as the **Moore-Penrose Pseudoinverse** (or *general pseudoinverse*), represented by the compact *dagger* notation:\n",
    "\n",
    "$$A^{\\dagger}\\triangleq (A^{\\top}A)^{-1}A^{\\top}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if we take:\n",
    "$$A_2 = \\begin{bmatrix} 1 & 1 & 1 \\\\\n",
    "-1 & 2 & 4 \n",
    "\\end{bmatrix}$$ and\n",
    "\n",
    "$$b_2 = \\begin{bmatrix} 10 \\\\\n",
    "4\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "we can still compute *a* solution (out of the infinitely-many solutions) to this problem, known as the *least-squares* solution, using the **psueodinverse**:\n",
    "\n",
    "$$x_{2,LS}=A_2^{\\dagger}b$$\n",
    "\n",
    "This is known as the *least-squares* solution, because it is equivalent to finding the *weights* of the linear regression model between the two datapoints $X = \\begin{bmatrix} 1 & 1 & 1 \\\\\n",
    "-1 & 2 & 4 \n",
    "\\end{bmatrix}$ and two corresponding outputs $y=\\begin{bmatrix} 10 \\\\\n",
    "4\n",
    "\\end{bmatrix}$.\n",
    "\n",
    "Now let's perform this psuedoinverse operation in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.]\n",
      " [3.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "A2 = np.array([[1,1,1],[-1,2,4]])\n",
    "b = np.array([[10],[4]])\n",
    "A2_dagger = np.linalg.pinv(A2)\n",
    "x2_LS = np.dot(A2_dagger,b)\n",
    "print(x2_LS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's again perform our usual sanity check to confirm this is indeed a solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.]\n",
      " [ 4.]]\n",
      "[[10]\n",
      " [ 4]]\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(A2,x2_LS))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the last example, let's perform the psueodinverse operation on matrix $A_3$ and see whether an *exact* solution exists. If no *exact* solution exists, then the problem is *overdefined*, i.e. there are four equations explaining three variables, with one equation contradicting the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A3 = np.array([[1,1,1],[2,1,1],[-1,2,4],[1,2,5]])\n",
    "b = b = np.array([[10],[5],[4],[10]])\n",
    "A3_dagger = np.linalg.pinv(A3)\n",
    "x3_LS = np.dot(A3_dagger,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if $A_3 x_{3,LS}$ gives the exact values for $b$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.03496503]\n",
      " [8.08391608]\n",
      " [5.32167832]\n",
      " [9.11888112]]\n",
      "[[10]\n",
      " [ 5]\n",
      " [ 4]\n",
      " [10]]\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(A3,x3_LS))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, it doesn't, therefore $A_3$ represents an *overdefined* problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Solving systems of non-linear equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine now that you have an engineering problem which boils down to the following equations:\n",
    "\n",
    "$$x_1 x_2-log_{10}(x_1)=1$$\n",
    "$$x_1^2+x_2^2=100.04$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a **non-linear** system, because it involves the variable-coupling term $x_1 x_2$ as well as non-linear functions of both $x_1$ and $x_2$ individually - specifically, $log_{10}(x_1)$, $x_1^2$, and $x_2^2$.\n",
    "\n",
    "Matrix inverses and psuedo-inverses are useless here, since those only work for linear systems. So how do we solve this? \n",
    "\n",
    "Fortunately, in your introductory numerical operations course (CHBE230 or equivalent), you learned about the technique of **root-finding**. So let's transform the previous problem into a suitable form for root-finding.\n",
    "\n",
    "First, we re-write the problem as:\n",
    "$$x_1 x_2-log_{10}(x_1)-1=0$$\n",
    "$$x_1^2+x_2^2-100.04=0$$\n",
    "\n",
    "Then we define a function $F=\\begin{bmatrix}f_1 \\\\ f_2 \\end{bmatrix}$ acting on both variables $x=\\begin{bmatrix}x_1 \\\\ x_2 \\end{bmatrix}$ such that:\n",
    "$$F(x)=\\begin{bmatrix}f_1 \\bigg(\\begin{bmatrix}x_1 \\\\ x_2 \\end{bmatrix} \\bigg) \\\\ f_2 \\bigg(\\begin{bmatrix}x_1 \\\\ x_2 \\end{bmatrix} \\bigg) \\end{bmatrix}=0$$\n",
    "\n",
    "Now we can see that $f_1$ and $f_2$ must equal to the re-written expressions above. We can now root-find this 2-dimensional function $F$ using many methods, including Newton's method, Broyden, Krylov, etc. Fortunately, *scipy* has a built-in function to do this, so let's use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First we define big F, and recall that Python starts indices at 0 and not 1!\n",
    "def bigF(x):\n",
    "    return np.array([x[0]*x[1] - np.log10(x[0]) - 1.0,np.power(x[0],2) + np.power(x[1],2) - 100.04])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's find the solution:\n",
    "x_init = np.array([[1],[1]]) # Initialization\n",
    "\n",
    "from scipy import optimize\n",
    "sol = optimize.root(bigF, x_init, method='hybr')\n",
    "x_sol=sol.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, let's perform a sanity check on these solutions, to ensure they evaluate to zero (within precision):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.77924686e-09, 1.20848910e-07])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigF(x_sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all there is to non-linear systems! Note that the cases of *underdefined* and *overdefinde* still exist, but neither possess well-defined/recognizable forms as in the case of linear systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
